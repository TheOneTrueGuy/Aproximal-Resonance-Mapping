{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install torch transformers scikit-learn ripser scipy umap-learn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F6mWiNZSRHxg",
        "outputId": "19db24c8-2b0d-41f6-f001-3478f7e63f3b"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.56.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Collecting ripser\n",
            "  Downloading ripser-0.6.12-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.7 kB)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (1.16.2)\n",
            "Requirement already satisfied: umap-learn in /usr/local/lib/python3.12/dist-packages (0.5.9.post2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.19.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.4.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.35.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.0)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.6.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: Cython in /usr/local/lib/python3.12/dist-packages (from ripser) (3.0.12)\n",
            "Collecting persim (from ripser)\n",
            "  Downloading persim-0.3.8-py3-none-any.whl.metadata (3.8 kB)\n",
            "Requirement already satisfied: numba>=0.51.2 in /usr/local/lib/python3.12/dist-packages (from umap-learn) (0.60.0)\n",
            "Requirement already satisfied: pynndescent>=0.5 in /usr/local/lib/python3.12/dist-packages (from umap-learn) (0.5.13)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.1.10)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.12/dist-packages (from numba>=0.51.2->umap-learn) (0.43.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Collecting deprecated (from persim->ripser)\n",
            "  Downloading Deprecated-1.2.18-py2.py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting hopcroftkarp (from persim->ripser)\n",
            "  Downloading hopcroftkarp-1.2.5.tar.gz (16 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from persim->ripser) (3.10.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2025.8.3)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.12/dist-packages (from deprecated->persim->ripser) (1.17.3)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->persim->ripser) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib->persim->ripser) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->persim->ripser) (4.60.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->persim->ripser) (1.4.9)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib->persim->ripser) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->persim->ripser) (3.2.4)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib->persim->ripser) (2.9.0.post0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib->persim->ripser) (1.17.0)\n",
            "Downloading ripser-0.6.12-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (827 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m827.3/827.3 kB\u001b[0m \u001b[31m47.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading persim-0.3.8-py3-none-any.whl (48 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.6/48.6 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading Deprecated-1.2.18-py2.py3-none-any.whl (10.0 kB)\n",
            "Building wheels for collected packages: hopcroftkarp\n",
            "  Building wheel for hopcroftkarp (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for hopcroftkarp: filename=hopcroftkarp-1.2.5-py2.py3-none-any.whl size=18104 sha256=ded84952137940e61af86a6aaf19658e17f731cc2716d7b0e084f33aeba8e9e4\n",
            "  Stored in directory: /root/.cache/pip/wheels/2a/fd/fe/f4b8fd82894e1d9e04040ef41dc5ae6eb7a8e9b0ef5a9402fe\n",
            "Successfully built hopcroftkarp\n",
            "Installing collected packages: hopcroftkarp, deprecated, persim, ripser\n",
            "Successfully installed deprecated-1.2.18 hopcroftkarp-1.2.5 persim-0.3.8 ripser-0.6.12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hJCN261WRHvl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_d-9cCbyQ5wf",
        "outputId": "b3d5183a-ffeb-431f-f692-1c4efc45d069"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Computed manifold basis with shape: (4, 768)\n",
            "Processing prompt 1/5...\n",
            "Processing prompt 2/5...\n",
            "Processing prompt 3/5...\n",
            "Processing prompt 4/5...\n",
            "Processing prompt 5/5...\n",
            "Spectral embedding shape: (5, 3)\n",
            "Descriptor vector (manifold-aware): [4.17819798e-01 2.91416734e-01 2.00587690e-01 8.86625499e-02\n",
            " 1.48228987e-03 1.80561765e-05 1.27104044e+00 2.40331578e+00\n",
            " 0.00000000e+00]\n",
            "Target signature (from 'The capital of Italy is'): [5.2048963e-01 2.6041636e-01 1.4006966e-01 7.7772535e-02 1.2239203e-03\n",
            " 1.3758596e-05]\n",
            "Steered next-token: The capital of Gerhard-Belsen, Germany, on Friday said it would not comment on the decision.\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " score: 2.0891204\n"
          ]
        }
      ],
      "source": [
        "# ARM_transformer_scaffold.py\n",
        "# Requires: torch, transformers, numpy, scikit-learn, ripser, scipy, umap-learn (install via pip)\n",
        "# pip install torch transformers scikit-learn ripser scipy umap-learn\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.neighbors import kneighbors_graph\n",
        "from sklearn.manifold import spectral_embedding\n",
        "from ripser import ripser\n",
        "from sklearn.metrics import pairwise_distances\n",
        "from typing import List, Tuple, Dict, Any\n",
        "import math\n",
        "\n",
        "# -----------------------\n",
        "# Configuration / defaults\n",
        "# -----------------------\n",
        "MODEL_NAME = \"distilgpt2\"   # small, efficient; switch to \"gpt2\" if you prefer\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# ARM hyperparams (safe defaults)\n",
        "N_SEEDS = 200\n",
        "PROBES_PER_SEED = 16\n",
        "STEPS_PER_PROBE = 9\n",
        "EPS = 0.03                 # perturbation magnitude (relative to hidden vector norm)\n",
        "LAYER_TO_PROBE = 6         # index of transformer block to inject perturbations (0-based)\n",
        "NEIGHBOR_PCA_SAMPLES = 128 # for local PCA when available\n",
        "MANIFOLD_MODES = 8         # Number of principal components to use for manifold\n",
        "\n",
        "# -----------------------\n",
        "# Utilities: load model\n",
        "# -----------------------\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
        "model = AutoModelForCausalLM.from_pretrained(MODEL_NAME, output_hidden_states=True).to(DEVICE)\n",
        "model.eval()\n",
        "\n",
        "# Helper: get token ids and attention mask\n",
        "def encode_prompt(prompt: str):\n",
        "    toks = tokenizer(prompt, return_tensors=\"pt\")\n",
        "    return toks[\"input_ids\"].to(DEVICE), toks[\"attention_mask\"].to(DEVICE)\n",
        "\n",
        "# -----------------------\n",
        "# Core: run forward from a chosen layer (block-wise)\n",
        "# -----------------------\n",
        "# We'll use the model.transformer.* components directly so we can inject altered hidden states.\n",
        "# For distilgpt2/gpt2 HF models, the transformer body is model.transformer consisting of:\n",
        "# - wte (token embeddings), wpe (position embeddings), drop, and h = list of blocks, ln_f.\n",
        "#\n",
        "# Strategy:\n",
        "# 1) Build initial hidden states (token embeddings + positions) up to the layer to probe.\n",
        "# 2) Optionally modify the residual stream at that layer (add delta).\n",
        "# 3) Run remaining transformer blocks from that layer onward to get final logits/hidden states.\n",
        "\n",
        "def build_initial_hidden(input_ids: torch.LongTensor):\n",
        "    # returns hidden states BEFORE block 0 (embedding+pos), shape (batch, seq_len, d_model)\n",
        "    wte = model.transformer.wte(input_ids)        # token embeddings\n",
        "    seq_len = input_ids.shape[1]\n",
        "    position_ids = torch.arange(seq_len, dtype=torch.long, device=DEVICE).unsqueeze(0)\n",
        "    wpe = model.transformer.wpe(position_ids)\n",
        "    hidden = wte + wpe  # shape batch x seq x d_model\n",
        "    hidden = model.transformer.drop(hidden)\n",
        "    return hidden\n",
        "\n",
        "def forward_from_layer(hidden: torch.Tensor, start_layer: int, attention_mask: torch.Tensor=None):\n",
        "    \"\"\"\n",
        "    hidden: (batch, seq, d_model) hidden state to feed to block start_layer\n",
        "    returns: final logits, final hidden, and list of intermediate hidden states (per layer)\n",
        "    \"\"\"\n",
        "    h = hidden\n",
        "    intermediates = []\n",
        "    # blocks are modules in model.transformer.h (list-like)\n",
        "    for i, block in enumerate(model.transformer.h):\n",
        "        if i < start_layer:\n",
        "            continue\n",
        "        h = block(h)[0] if isinstance(block(h), tuple) else block(h)\n",
        "        intermediates.append(h)\n",
        "    # final layer norm\n",
        "    h = model.transformer.ln_f(h)\n",
        "    # lm head (tie weights with wte)\n",
        "    # reshape for lm head: (batch*seq, d_model)\n",
        "    logits = F.linear(h, model.transformer.wte.weight)  # tied weights\n",
        "    return logits, h, intermediates\n",
        "\n",
        "# -----------------------\n",
        "# Seed / probe generation\n",
        "# -----------------------\n",
        "def get_seed_hidden(prompt: str, layer_idx: int) -> torch.Tensor:\n",
        "    \"\"\"\n",
        "    Returns hidden state at layer_idx just BEFORE running block layer_idx.\n",
        "    shape: (seq_len, d_model) - batch dim removed for simplicity\n",
        "    \"\"\"\n",
        "    input_ids, attn_mask = encode_prompt(prompt)\n",
        "    hidden = build_initial_hidden(input_ids)  # batch x seq x d\n",
        "    # run blocks up to layer_idx-1 to get hidden state to modify\n",
        "    h = hidden\n",
        "    for i, block in enumerate(model.transformer.h):\n",
        "        if i >= layer_idx:\n",
        "            break\n",
        "        h = block(h)[0] if isinstance(block(h), tuple) else block(h)\n",
        "    # h is batch x seq x d; return squeeze(0)\n",
        "    return h.squeeze(0).detach().cpu()  # move to CPU numpy-friendly\n",
        "\n",
        "def sample_probes_for_hidden(hidden_vec: np.ndarray, k: int = PROBES_PER_SEED, eps: float = EPS, manifold_basis: np.ndarray = None):\n",
        "    \"\"\"\n",
        "    hidden_vec: (seq_len, d) array (we'll flatten sequence dimension to treat as a single vector or pool)\n",
        "    Return: probe_deltas shape (k, d) or (k, seq_len, d)\n",
        "    Approach: get global direction sampling in hidden-space.\n",
        "    - If manifold_basis is provided, sample directions within the manifold subspace.\n",
        "    - Otherwise, start with isotropic Gaussian directions normalized,\n",
        "      then scale to magnitude eps * ||hidden_vec|| (per token or pooled).\n",
        "    \"\"\"\n",
        "    # pool hidden to a single vector per seed (mean over tokens) for direction construction,\n",
        "    # but we will expand deltas per token when injecting.\n",
        "    pooled = hidden_vec.mean(axis=0)   # (d,)\n",
        "    d = pooled.shape[0]\n",
        "    rng = np.random.default_rng()\n",
        "\n",
        "    if manifold_basis is not None and manifold_basis.size > 0:\n",
        "        # Sample random coefficients for the manifold basis\n",
        "        coeffs = rng.normal(size=(k, manifold_basis.shape[0])) # Use shape[0] as it's n_components\n",
        "        # Construct directions as linear combinations of basis vectors\n",
        "        dirs = coeffs @ manifold_basis  # (k, d) - This should now produce k vectors of dimension d\n",
        "    else:\n",
        "        dirs = rng.normal(size=(k, d))\n",
        "\n",
        "    dirs = dirs / (np.linalg.norm(dirs, axis=1, keepdims=True) + 1e-12)\n",
        "    hidden_norm = np.linalg.norm(pooled) + 1e-12\n",
        "    scale = eps * hidden_norm\n",
        "    dirs = dirs * scale\n",
        "    return dirs  # (k, d)\n",
        "\n",
        "def expand_delta_to_sequence(delta_vec: np.ndarray, seq_len: int):\n",
        "    # replicate delta_vec for each token position (simple approach)\n",
        "    return np.tile(delta_vec[None, :], (seq_len, 1))  # (seq_len, d)\n",
        "\n",
        "# -----------------------\n",
        "# Probe path: generate small path along a direction\n",
        "# -----------------------\n",
        "def build_probe_path(hidden_base: np.ndarray, dir_vec: np.ndarray, steps: int = STEPS_PER_PROBE, tau: float = 1.0):\n",
        "    \"\"\"\n",
        "    hidden_base: (seq_len, d)\n",
        "    dir_vec: (d,) pooled direction; will be expanded across seq positions\n",
        "    Returns: list of perturbed hidden tensors (steps long)\n",
        "    \"\"\"\n",
        "    seq_len = hidden_base.shape[0]\n",
        "    # Ensure dir_vec is (d,) before expanding\n",
        "    if dir_vec.ndim > 1:\n",
        "        # If dir_vec is (1, d), squeeze it\n",
        "        dir_vec = dir_vec.squeeze(0)\n",
        "    dir_seq = expand_delta_to_sequence(dir_vec, seq_len)  # (seq_len, d)\n",
        "    ts = np.linspace(-tau, tau, steps)\n",
        "    path = [hidden_base + (t * dir_seq) for t in ts]\n",
        "    return path, ts\n",
        "\n",
        "# -----------------------\n",
        "# Activation / response collection\n",
        "# -----------------------\n",
        "def activation_matrix_for_seed(prompt: str, layer_idx: int, k: int = PROBES_PER_SEED, m: int = STEPS_PER_PROBE, eps: float = EPS, manifold_basis: np.ndarray = None):\n",
        "    \"\"\"\n",
        "    For one seed prompt, sample k probes, each with m steps; forward from layer_idx\n",
        "    Collect features for each sample (e.g., final logits pooled, or final hidden pooled)\n",
        "    Return: A matrix of shape (k*m, f) for downstream analysis.\n",
        "    \"\"\"\n",
        "    hidden_base = get_seed_hidden(prompt, layer_idx).numpy()  # (seq_len, d)\n",
        "    seq_len, d = hidden_base.shape\n",
        "    deltas = sample_probes_for_hidden(hidden_base, k=k, eps=eps, manifold_basis=manifold_basis) # deltas shape (k, d)\n",
        "    rows = []\n",
        "    for j in range(k):\n",
        "        # Pass each individual delta vector (shape (d,)) to build_probe_path\n",
        "        path, ts = build_probe_path(hidden_base, deltas[j, :], steps=m)\n",
        "        for hidden_pert in path:\n",
        "            # run from layer_idx with this perturbed hidden\n",
        "            # convert to tensor with batch dim\n",
        "            h_t = torch.tensor(hidden_pert[None, :, :], dtype=torch.float32, device=DEVICE)\n",
        "            logits, final_h, intermediates = forward_from_layer(h_t, start_layer=layer_idx, attention_mask=None)\n",
        "            # choose feature vector to represent response:\n",
        "            # Option A: pooled logits over last token\n",
        "            # last_token_logits = logits[0, -1, :].detach().cpu().numpy()  # (vocab,)\n",
        "            # Option B (more compact): mean-pooled final hidden representation\n",
        "            feat = final_h.squeeze(0).mean(dim=0).detach().cpu().numpy()  # (d,)\n",
        "            rows.append(feat)\n",
        "    A = np.stack(rows, axis=0)  # (k*m, f) where f == d in this choice\n",
        "    return A\n",
        "\n",
        "# -----------------------\n",
        "# Resonance signature (SVD-based)\n",
        "# -----------------------\n",
        "def resonance_signature(A: np.ndarray, n_modes: int = 8) -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    Compute SVD stats and compact resonance signature for activation matrix A (n_samples x f).\n",
        "    Returns dict with normalized singular values, entropy, participation ratio, top modes.\n",
        "    \"\"\"\n",
        "    # center\n",
        "    A0 = A - A.mean(axis=0, keepdims=True)\n",
        "    # SVD (economy)\n",
        "    U, s, Vt = np.linalg.svd(A0, full_matrices=False)\n",
        "    s = np.maximum(s, 1e-12)\n",
        "    s_norm = s / s.sum()\n",
        "    entropy = -np.sum(s_norm * np.log(s_norm + 1e-12))\n",
        "    # participation ratio (measure of mode concentration)\n",
        "    pr = (s**2).sum()**2 / (np.sum(s**4) + 1e-12)\n",
        "    sig = {\n",
        "        \"singular_values\": s[:n_modes],\n",
        "        \"s_norm\": s_norm[:n_modes],\n",
        "        \"entropy\": float(entropy),\n",
        "        \"participation\": float(pr),\n",
        "        # optionally return top singular vectors (Vt[:n_modes,:]) if needed\n",
        "    }\n",
        "    return sig\n",
        "\n",
        "# -----------------------\n",
        "# Local topology via persistent homology\n",
        "# -----------------------\n",
        "def local_persistence_diagram(A: np.ndarray, maxdim: int = 1) -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    Compute persistence diagrams from the sample points A (n_points x f).\n",
        "    Use pairwise distances -> ripser with distance matrix True.\n",
        "    Returns ripser output (dgms).\n",
        "    \"\"\"\n",
        "    # compute pairwise distances to reduce memory in ripser call\n",
        "    D = pairwise_distances(A)\n",
        "    r = ripser(D, distance_matrix=True, maxdim=maxdim)\n",
        "    dgms = r[\"dgms\"]  # list of arrays for dimensions [0], [1], ...\n",
        "    return {\"diagrams\": dgms}\n",
        "\n",
        "# -----------------------\n",
        "# Descriptor assembly for one seed\n",
        "# -----------------------\n",
        "def descriptor_for_prompt(prompt: str, layer_idx: int, manifold_basis: np.ndarray = None):\n",
        "    \"\"\"\n",
        "    Run probes, compute A, then compute resonance signature + persistence.\n",
        "    Return a compact descriptor dict and flattened vector for graph building.\n",
        "    \"\"\"\n",
        "    A = activation_matrix_for_seed(prompt, layer_idx, manifold_basis=manifold_basis)\n",
        "    R = resonance_signature(A)\n",
        "    PD = local_persistence_diagram(A)\n",
        "    # flatten descriptor to a vector: use top-n singular values + entropy + participation + persistence stats\n",
        "    top_sv = R[\"s_norm\"][:6]\n",
        "    entropy = R[\"entropy\"]\n",
        "    part = R[\"participation\"]\n",
        "    # summary persistence features: count of significant 1D features (persistence > threshold)\n",
        "    d1 = PD[\"diagrams\"][1] if len(PD[\"diagrams\"]) > 1 else np.zeros((0,2))\n",
        "    pers_threshold = 0.05 * np.max(pairwise_distances(A)) if A.shape[0] > 1 else 0  # heuristic, handle single point case\n",
        "    n_1d_significant = np.sum((d1[:,1] - d1[:,0]) > pers_threshold) if d1.size else 0\n",
        "    vec = np.concatenate([top_sv, [entropy, part, n_1d_significant]])\n",
        "    return {\"A\": A, \"R\": R, \"PD\": PD, \"vec\": vec, \"prompt\": prompt}\n",
        "\n",
        "\n",
        "# -----------------------\n",
        "# Manifold representation\n",
        "# -----------------------\n",
        "def compute_manifold_basis(example_prompts: List[str], layer_idx: int, n_components: int = MANIFOLD_MODES):\n",
        "    \"\"\"\n",
        "    Compute hidden states for example prompts and find the top PCA components.\n",
        "    Returns the principal components (basis vectors).\n",
        "    \"\"\"\n",
        "    hidden_states = []\n",
        "    for prompt in example_prompts:\n",
        "        hidden = get_seed_hidden(prompt, layer_idx).numpy()  # (seq_len, d)\n",
        "        # Pool across sequence length for simplicity\n",
        "        pooled_hidden = hidden.mean(axis=0)  # (d,)\n",
        "        hidden_states.append(pooled_hidden)\n",
        "    H = np.stack(hidden_states, axis=0)  # (n_examples, d)\n",
        "    # Ensure n_components does not exceed the number of samples\n",
        "    n_components_actual = min(n_components, H.shape[0])\n",
        "    if n_components_actual == 0:\n",
        "        print(\"Warning: No manifold prompts provided, cannot compute manifold basis.\")\n",
        "        return np.array([]) # Return empty array if no prompts\n",
        "    pca = PCA(n_components=n_components_actual)\n",
        "    pca.fit(H)\n",
        "    return pca.components_  # (n_components_actual, d)\n",
        "\n",
        "\n",
        "# -----------------------\n",
        "# Build global atlas from many seeds\n",
        "# -----------------------\n",
        "def build_atlas(prompts: List[str], layer_idx: int, n_neighbors: int = 8, manifold_basis: np.ndarray = None):\n",
        "    \"\"\"\n",
        "    Build a global atlas of prompts by computing descriptors and their spectral embedding.\n",
        "    Can accept a larger list of prompts.\n",
        "    \"\"\"\n",
        "    descriptors = []\n",
        "    vecs = []\n",
        "    for i, p in enumerate(prompts):\n",
        "        # Add a progress indicator for potentially large numbers of prompts\n",
        "        print(f\"Processing prompt {i+1}/{len(prompts)}...\")\n",
        "        d = descriptor_for_prompt(p, layer_idx, manifold_basis=manifold_basis)\n",
        "        descriptors.append(d)\n",
        "        vecs.append(d[\"vec\"])\n",
        "    X = np.stack(vecs, axis=0)  # n_seeds x dim\n",
        "    # kNN graph adjacency (distance)\n",
        "    W = kneighbors_graph(X, n_neighbors=n_neighbors, mode=\"distance\", include_self=False).toarray()\n",
        "    # spectral embedding for visualization\n",
        "    emb = spectral_embedding(W + W.T, n_components=3)\n",
        "    return {\"descriptors\": descriptors, \"X\": X, \"W\": W, \"emb\": emb}\n",
        "\n",
        "# -----------------------\n",
        "# Simple iterative (greedy) proximal steering operator\n",
        "# -----------------------\n",
        "def steer_toward_manifold_resonance(seed_prompt: str, target_signature: np.ndarray, layer_idx: int, manifold_basis: np.ndarray, iters: int = 6, candidates: int = 12, max_new_tokens: int = 100):\n",
        "    \"\"\"\n",
        "    Iterative greedy search to steer generation toward a target manifold resonance.\n",
        "    Generates `max_new_tokens` iteratively.\n",
        "    \"\"\"\n",
        "    input_ids = tokenizer.encode(seed_prompt, return_tensors=\"pt\").to(DEVICE)\n",
        "    generated_tokens = input_ids.tolist()[0]\n",
        "\n",
        "    for _ in range(max_new_tokens):\n",
        "        current_text = tokenizer.decode(generated_tokens)\n",
        "        # get hidden state at the layer before probing for the *current* sequence\n",
        "        # need to re-run the initial layers for the current sequence to get the updated hidden state\n",
        "        input_ids_current = tokenizer.encode(current_text, return_tensors=\"pt\").to(DEVICE)\n",
        "        hidden_base = build_initial_hidden(input_ids_current) # batch x seq x d\n",
        "        # run blocks up to layer_idx-1\n",
        "        h = hidden_base\n",
        "        for i, block in enumerate(model.transformer.h):\n",
        "            if i >= layer_idx:\n",
        "                break\n",
        "            h = block(h)[0] if isinstance(block(h), tuple) else block(h)\n",
        "        current_hidden = h.squeeze(0).detach().cpu().numpy() # (seq_len, d)\n",
        "\n",
        "\n",
        "        seq_len, d = current_hidden.shape\n",
        "\n",
        "        best_score = float(\"inf\")\n",
        "        best_delta = None\n",
        "\n",
        "        # Propose candidate deltas restricted to manifold directions\n",
        "        rng = np.random.default_rng()\n",
        "        coeffs = rng.normal(size=(candidates, manifold_basis.shape[0]))\n",
        "        cand_dirs = coeffs @ manifold_basis  # (candidates, d)\n",
        "\n",
        "        # Normalize and scale candidates\n",
        "        cand_dirs = cand_dirs / (np.linalg.norm(cand_dirs, axis=1, keepdims=True) + 1e-12)\n",
        "        scales = np.linspace(-EPS, EPS, 5)\n",
        "\n",
        "        for cd in cand_dirs:\n",
        "            for s in scales:\n",
        "                delta = cd * s * (np.linalg.norm(current_hidden.mean(axis=0)) + 1e-12)\n",
        "                perturbed_hidden = current_hidden + expand_delta_to_sequence(delta, seq_len)\n",
        "\n",
        "                # forward and compute final pooled hidden (cheap shortcut)\n",
        "                h_t = torch.tensor(perturbed_hidden[None, :, :], dtype=torch.float32, device=DEVICE)\n",
        "                _, final_h, _ = forward_from_layer(h_t, start_layer=layer_idx)\n",
        "                feat = final_h.squeeze(0).mean(dim=0).detach().cpu().numpy()\n",
        "\n",
        "                # compute simple proxy signature: projection on top eigenvector (cheap)\n",
        "                # Here we create a tiny matrix with just this feat to plug into resonance_signature (works but trivial)\n",
        "                sig = resonance_signature(np.stack([feat], axis=0))\n",
        "                # distance: compare sig[\"s_norm\"] to target_signature (assumed same length)\n",
        "                cand_vec = sig[\"s_norm\"][:len(target_signature)]\n",
        "                score = np.linalg.norm(cand_vec - target_signature)\n",
        "\n",
        "                if score < best_score:\n",
        "                    best_score = score\n",
        "                    best_delta = delta # Store the delta that gave the best score\n",
        "\n",
        "        # Apply the best delta to the hidden state for the next token prediction\n",
        "        if best_delta is not None:\n",
        "             current_hidden_perturbed = current_hidden + expand_delta_to_sequence(best_delta, seq_len)\n",
        "        else:\n",
        "             # If no good delta found, use the original hidden state (or handle as needed)\n",
        "             current_hidden_perturbed = current_hidden\n",
        "\n",
        "\n",
        "        # forward with the potentially perturbed hidden state to get logits for next token\n",
        "        h_t_perturbed = torch.tensor(current_hidden_perturbed[None, :, :], dtype=torch.float32, device=DEVICE)\n",
        "        logits, new_hidden, _ = forward_from_layer(h_t_perturbed, start_layer=layer_idx) # Get the hidden state for the next token\n",
        "\n",
        "        # predict next token (greedy)\n",
        "        next_token_id = torch.argmax(logits[0, -1, :]).item()\n",
        "\n",
        "        # append to generated sequence\n",
        "        generated_tokens.append(next_token_id)\n",
        "\n",
        "        # Optional: add a condition to stop generation (e.g., a stop token)\n",
        "        if next_token_id == tokenizer.eos_token_id: # Example: stop on EOS token\n",
        "            break\n",
        "\n",
        "\n",
        "    return tokenizer.decode(generated_tokens), best_score # Return the full generated sequence and the final score\n",
        "\n",
        "\n",
        "# -----------------------\n",
        "# Example usage\n",
        "# -----------------------\n",
        "if __name__ == \"__main__\":\n",
        "    # quick test prompts for atlas\n",
        "    atlas_prompts = [\n",
        "        \"The capital of France is\",\n",
        "        \"The capital of Germany is\",\n",
        "        \"I love reading about physics because\",\n",
        "        \"The chef seasoned the soup with\",\n",
        "        \"Quantum entanglement is best described as\"\n",
        "    ]\n",
        "\n",
        "    # Example prompts for defining a manifold (e.g., \"Paris-style factual completions\")\n",
        "    manifold_prompts = [\n",
        "        \"The capital of Italy is\",\n",
        "        \"The largest city in Spain is\",\n",
        "        \"Mount Everest is located in\",\n",
        "        \"The currency of Japan is\"\n",
        "    ]\n",
        "\n",
        "    # Compute manifold basis\n",
        "    manifold_basis = compute_manifold_basis(manifold_prompts, layer_idx=LAYER_TO_PROBE, n_components=MANIFOLD_MODES)\n",
        "    print(f\"Computed manifold basis with shape: {manifold_basis.shape}\")\n",
        "\n",
        "    # compute atlas (descriptors may be somewhat slow; reduce N_SEEDS for testing)\n",
        "    # Pass the manifold basis to build_atlas to potentially see how descriptors within the manifold space cluster\n",
        "    atlas = build_atlas(atlas_prompts, layer_idx=LAYER_TO_PROBE, n_neighbors=3, manifold_basis=manifold_basis)\n",
        "    print(\"Spectral embedding shape:\", atlas[\"emb\"].shape)\n",
        "\n",
        "    # pick a seed and compute its descriptor (using the manifold basis)\n",
        "    d = descriptor_for_prompt(\"The capital of France is\", layer_idx=LAYER_TO_PROBE, manifold_basis=manifold_basis)\n",
        "    print(\"Descriptor vector (manifold-aware):\", d[\"vec\"])\n",
        "\n",
        "    # Example target signature for steering (pick a seed's signature within the manifold)\n",
        "    # For demonstration, let's use the signature of \"The capital of Italy is\" as the target\n",
        "    target_descriptor = descriptor_for_prompt(\"The capital of Italy is\", layer_idx=LAYER_TO_PROBE, manifold_basis=manifold_basis)\n",
        "    target_sig = target_descriptor[\"R\"][\"s_norm\"][:6]\n",
        "    print(\"Target signature (from 'The capital of Italy is'):\", target_sig)\n",
        "\n",
        "\n",
        "    out_token, score = steer_toward_manifold_resonance(\"The capital of Ger\", target_sig, layer_idx=LAYER_TO_PROBE, manifold_basis=manifold_basis)\n",
        "    print(\"Steered next-token:\", out_token, \"score:\", score)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "043b71d6"
      },
      "source": [
        "!pip install -q gradio"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 648
        },
        "id": "8cd5dcd0",
        "outputId": "afeffd8f-6967-4965-db74-206ce40c013e"
      },
      "source": [
        "import gradio as gr\n",
        "import re # Import regular expression module for splitting sentences\n",
        "\n",
        "def split_sentences(text):\n",
        "    # Split text into sentences using common punctuation marks\n",
        "    sentences = re.split(r'(?<!\\w\\.\\w.)(?<![A-Z][a-z]\\.)(?<=\\.|\\?|\\!)\\s', text)\n",
        "    return [s.strip() for s in sentences if s.strip()]\n",
        "\n",
        "def run_steering_gradio(prompt, manifold_file):\n",
        "    # The 'prompt' input is not used in this function, but kept for the function signature compatibility with Gradio\n",
        "    if manifold_file is None:\n",
        "        return \"Please upload a text file with manifold prompts.\"\n",
        "\n",
        "    current_manifold_prompts = []\n",
        "    try:\n",
        "        # Read manifold prompts from the uploaded file using its path\n",
        "        with open(manifold_file.name, 'r', encoding='utf-8') as f:\n",
        "             file_content = f.read()\n",
        "        current_manifold_prompts = split_sentences(file_content)\n",
        "    except Exception as e:\n",
        "        return f\"Error reading or processing manifold file: {e}\"\n",
        "\n",
        "    if not current_manifold_prompts:\n",
        "        return \"No manifold prompts found in the uploaded file.\"\n",
        "\n",
        "    output_text = f\"Using manifold prompts ({len(current_manifold_prompts)}): {current_manifold_prompts[:5]}...\\n\" # Show only first 5 for brevity\n",
        "\n",
        "    try:\n",
        "        # Compute manifold basis based on current input\n",
        "        current_manifold_basis = compute_manifold_basis(current_manifold_prompts, layer_idx=LAYER_TO_PROBE, n_components=MANIFOLD_MODES)\n",
        "        output_text += f\"Computed manifold basis with shape: {current_manifold_basis.shape}\\n\"\n",
        "\n",
        "        # For demonstration, use the signature of the first manifold prompt as the target\n",
        "        if current_manifold_prompts:\n",
        "             target_descriptor = descriptor_for_prompt(current_manifold_prompts[0], layer_idx=LAYER_TO_PROBE, manifold_basis=current_manifold_basis)\n",
        "             target_sig = target_descriptor[\"R\"][\"s_norm\"][:6]\n",
        "             output_text += f\"Target signature (from first manifold prompt): {target_sig}\\n\"\n",
        "        else:\n",
        "             # This case should theoretically not be reached due to the check above, but as a safeguard\n",
        "             output_text += \"No manifold prompts available to determine target signature.\\n\"\n",
        "             return output_text\n",
        "\n",
        "        # Store computed basis and target signature for testing phase\n",
        "        global current_manifold_basis_global, target_sig_global\n",
        "        current_manifold_basis_global = current_manifold_basis\n",
        "        target_sig_global = target_sig\n",
        "\n",
        "        output_text += \"\\nManifold constructed successfully. You can now test steering below.\\n\"\n",
        "\n",
        "\n",
        "    except Exception as e:\n",
        "        output_text += f\"An error occurred during manifold construction: {e}\\n\"\n",
        "        import traceback\n",
        "        output_text += traceback.format_exc()\n",
        "\n",
        "    return output_text\n",
        "\n",
        "def test_steering_gradio(test_prompt, max_tokens):\n",
        "    if not test_prompt:\n",
        "        return \"Please enter a prompt to test steering.\"\n",
        "\n",
        "    global current_manifold_basis_global, target_sig_global\n",
        "    if current_manifold_basis_global is None or target_sig_global is None:\n",
        "        return \"Please construct the manifold first by clicking the 'GO!' button in the 'Manifold Construction' tab.\"\n",
        "\n",
        "    output_text = f\"Testing steering for prompt: '{test_prompt}' with max tokens: {max_tokens}\\n\"\n",
        "\n",
        "    try:\n",
        "        # steer_toward_manifold_resonance now returns the full generated sequence\n",
        "        generated_sequence, score = steer_toward_manifold_resonance(test_prompt, target_sig_global, layer_idx=LAYER_TO_PROBE, manifold_basis=current_manifold_basis_global, max_new_tokens=max_tokens)\n",
        "        output_text += f\"Generated Sequence: {generated_sequence}\\n\"\n",
        "        output_text += f\"Final Score: {score}\\n\" # Display the final score if needed\n",
        "\n",
        "    except Exception as e:\n",
        "        output_text += f\"An error occurred during steering: {e}\\n\"\n",
        "        import traceback\n",
        "        output_text += traceback.format_exc()\n",
        "\n",
        "    return output_text\n",
        "\n",
        "\n",
        "# Initialize global variables\n",
        "current_manifold_basis_global = None\n",
        "target_sig_global = None\n",
        "\n",
        "\n",
        "# Create the Gradio interface\n",
        "with gr.Blocks() as demo:\n",
        "    gr.Markdown(\"## ARM Manifold Steering\")\n",
        "\n",
        "    with gr.Tab(\"Manifold Construction\"):\n",
        "        gr.Markdown(\"Upload a text file containing prompts to define the manifold. Each sentence will be treated as a separate prompt.\")\n",
        "        manifold_file_input = gr.File(label=\"Upload Manifold Prompts File\")\n",
        "        go_button = gr.Button(\"GO! Construct Manifold\")\n",
        "        construction_output = gr.Textbox(label=\"Construction Output\", lines=10, interactive=False)\n",
        "\n",
        "        go_button.click(\n",
        "            run_steering_gradio,\n",
        "            inputs=[gr.Textbox(visible=False), manifold_file_input], # Dummy prompt input for function signature\n",
        "            outputs=construction_output\n",
        "        )\n",
        "\n",
        "    with gr.Tab(\"Test Steering\"):\n",
        "        gr.Markdown(\"Enter a prompt prefix to see the next token steered towards the constructed manifold.\")\n",
        "        test_prompt_input = gr.Textbox(label=\"Enter Prompt Prefix\", lines=3)\n",
        "        max_tokens_input = gr.Number(label=\"Max Tokens to Generate\", value=400, precision=0)\n",
        "        test_button = gr.Button(\"Test Steering\")\n",
        "        test_output = gr.Textbox(label=\"Test Output\", lines=10, interactive=False)\n",
        "\n",
        "        test_button.click(\n",
        "            test_steering_gradio,\n",
        "            inputs=[test_prompt_input, max_tokens_input],\n",
        "            outputs=test_output\n",
        "        )\n",
        "\n",
        "\n",
        "demo.launch()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you are running Gradio on a hosted Jupyter notebook, which requires `share=True`. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://b95d738b0031bcedd6.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://b95d738b0031bcedd6.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a11feb96"
      },
      "source": [
        "import ipywidgets as widgets\n",
        "from IPython.display import display\n",
        "\n",
        "prompt_input = widgets.Textarea(\n",
        "    value='',\n",
        "    placeholder='Enter your prompt here',\n",
        "    description='Prompt:',\n",
        "    disabled=False,\n",
        "    layout={'width': '500px', 'height': '100px'}\n",
        ")\n",
        "\n",
        "manifold_prompts_input = widgets.Textarea(\n",
        "    value='\\n'.join(manifold_prompts), # Use existing manifold_prompts as default\n",
        "    placeholder='Enter manifold prompts (one per line)',\n",
        "    description='Manifold Prompts:',\n",
        "    disabled=False,\n",
        "    layout={'width': '500px', 'height': '150px'}\n",
        ")\n",
        "\n",
        "\n",
        "output_area = widgets.Output()\n",
        "\n",
        "run_button = widgets.Button(description=\"Run Steering\")\n",
        "\n",
        "def run_steering(b):\n",
        "    with output_area:\n",
        "        output_area.clear_output()\n",
        "        prompt = prompt_input.value\n",
        "        current_manifold_prompts = manifold_prompts_input.value.splitlines()\n",
        "\n",
        "        if not prompt:\n",
        "            print(\"Please enter a prompt.\")\n",
        "            return\n",
        "        if not current_manifold_prompts:\n",
        "            print(\"Please enter manifold prompts.\")\n",
        "            return\n",
        "\n",
        "        print(f\"Running steering for prompt: '{prompt}'\")\n",
        "        print(f\"Using manifold prompts: {current_manifold_prompts}\")\n",
        "\n",
        "        try:\n",
        "            # Recompute manifold basis based on current input\n",
        "            current_manifold_basis = compute_manifold_basis(current_manifold_prompts, layer_idx=LAYER_TO_PROBE, n_components=MANIFOLD_MODES)\n",
        "            print(f\"Computed manifold basis with shape: {current_manifold_basis.shape}\")\n",
        "\n",
        "            # For demonstration, use the signature of the first manifold prompt as the target\n",
        "            if current_manifold_prompts:\n",
        "                 target_descriptor = descriptor_for_prompt(current_manifold_prompts[0], layer_idx=LAYER_TO_PROBE, manifold_basis=current_manifold_basis)\n",
        "                 target_sig = target_descriptor[\"R\"][\"s_norm\"][:6]\n",
        "                 print(\"Target signature (from first manifold prompt):\", target_sig)\n",
        "            else:\n",
        "                 print(\"No manifold prompts provided to determine target signature.\")\n",
        "                 return\n",
        "\n",
        "\n",
        "            out_token, score = steer_toward_manifold_resonance(prompt, target_sig, layer_idx=LAYER_TO_PROBE, manifold_basis=current_manifold_basis)\n",
        "            print(\"Steered next-token:\", out_token, \"score:\", score)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"An error occurred: {e}\")\n",
        "\n",
        "\n",
        "run_button.on_click(run_steering)\n",
        "\n",
        "display(prompt_input, manifold_prompts_input, run_button, output_area)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}