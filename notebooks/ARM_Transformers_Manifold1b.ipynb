{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install torch transformers scikit-learn ripser scipy umap-learn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F6mWiNZSRHxg",
        "outputId": "19db24c8-2b0d-41f6-f001-3478f7e63f3b"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.56.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Collecting ripser\n",
            "  Downloading ripser-0.6.12-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.7 kB)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (1.16.2)\n",
            "Requirement already satisfied: umap-learn in /usr/local/lib/python3.12/dist-packages (0.5.9.post2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.19.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.4.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.35.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.0)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.6.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: Cython in /usr/local/lib/python3.12/dist-packages (from ripser) (3.0.12)\n",
            "Collecting persim (from ripser)\n",
            "  Downloading persim-0.3.8-py3-none-any.whl.metadata (3.8 kB)\n",
            "Requirement already satisfied: numba>=0.51.2 in /usr/local/lib/python3.12/dist-packages (from umap-learn) (0.60.0)\n",
            "Requirement already satisfied: pynndescent>=0.5 in /usr/local/lib/python3.12/dist-packages (from umap-learn) (0.5.13)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.1.10)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.12/dist-packages (from numba>=0.51.2->umap-learn) (0.43.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Collecting deprecated (from persim->ripser)\n",
            "  Downloading Deprecated-1.2.18-py2.py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting hopcroftkarp (from persim->ripser)\n",
            "  Downloading hopcroftkarp-1.2.5.tar.gz (16 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from persim->ripser) (3.10.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2025.8.3)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.12/dist-packages (from deprecated->persim->ripser) (1.17.3)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->persim->ripser) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib->persim->ripser) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->persim->ripser) (4.60.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->persim->ripser) (1.4.9)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib->persim->ripser) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->persim->ripser) (3.2.4)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib->persim->ripser) (2.9.0.post0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib->persim->ripser) (1.17.0)\n",
            "Downloading ripser-0.6.12-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (827 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m827.3/827.3 kB\u001b[0m \u001b[31m47.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading persim-0.3.8-py3-none-any.whl (48 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.6/48.6 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading Deprecated-1.2.18-py2.py3-none-any.whl (10.0 kB)\n",
            "Building wheels for collected packages: hopcroftkarp\n",
            "  Building wheel for hopcroftkarp (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for hopcroftkarp: filename=hopcroftkarp-1.2.5-py2.py3-none-any.whl size=18104 sha256=ded84952137940e61af86a6aaf19658e17f731cc2716d7b0e084f33aeba8e9e4\n",
            "  Stored in directory: /root/.cache/pip/wheels/2a/fd/fe/f4b8fd82894e1d9e04040ef41dc5ae6eb7a8e9b0ef5a9402fe\n",
            "Successfully built hopcroftkarp\n",
            "Installing collected packages: hopcroftkarp, deprecated, persim, ripser\n",
            "Successfully installed deprecated-1.2.18 hopcroftkarp-1.2.5 persim-0.3.8 ripser-0.6.12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hJCN261WRHvl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 436
        },
        "id": "_d-9cCbyQ5wf",
        "outputId": "4dd0bbbf-b5b2-4993-c6ef-8b15a7f52c89"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Computed manifold basis with shape: (4, 768)\n",
            "Processing prompt 1/5...\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "operands could not be broadcast together with shapes (5,768) (5,4) ",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2769523182.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    380\u001b[0m     \u001b[0;31m# compute atlas (descriptors may be somewhat slow; reduce N_SEEDS for testing)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m     \u001b[0;31m# Pass the manifold basis to build_atlas to potentially see how descriptors within the manifold space cluster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 382\u001b[0;31m     \u001b[0matlas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_atlas\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0matlas_prompts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer_idx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mLAYER_TO_PROBE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_neighbors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmanifold_basis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmanifold_basis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    383\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Spectral embedding shape:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0matlas\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"emb\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-2769523182.py\u001b[0m in \u001b[0;36mbuild_atlas\u001b[0;34m(prompts, layer_idx, n_neighbors, manifold_basis)\u001b[0m\n\u001b[1;32m    282\u001b[0m         \u001b[0;31m# Add a progress indicator for potentially large numbers of prompts\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Processing prompt {i+1}/{len(prompts)}...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 284\u001b[0;31m         \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdescriptor_for_prompt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmanifold_basis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmanifold_basis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    285\u001b[0m         \u001b[0mdescriptors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m         \u001b[0mvecs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"vec\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-2769523182.py\u001b[0m in \u001b[0;36mdescriptor_for_prompt\u001b[0;34m(prompt, layer_idx, manifold_basis)\u001b[0m\n\u001b[1;32m    229\u001b[0m     \u001b[0mReturn\u001b[0m \u001b[0ma\u001b[0m \u001b[0mcompact\u001b[0m \u001b[0mdescriptor\u001b[0m \u001b[0mdict\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mflattened\u001b[0m \u001b[0mvector\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mgraph\u001b[0m \u001b[0mbuilding\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m     \"\"\"\n\u001b[0;32m--> 231\u001b[0;31m     \u001b[0mA\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mactivation_matrix_for_seed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmanifold_basis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmanifold_basis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    232\u001b[0m     \u001b[0mR\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresonance_signature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m     \u001b[0mPD\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlocal_persistence_diagram\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-2769523182.py\u001b[0m in \u001b[0;36mactivation_matrix_for_seed\u001b[0;34m(prompt, layer_idx, k, m, eps, manifold_basis)\u001b[0m\n\u001b[1;32m    165\u001b[0m     \u001b[0mrows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 167\u001b[0;31m         \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_probe_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_base\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeltas\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    168\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhidden_pert\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m             \u001b[0;31m# run from layer_idx with this perturbed hidden\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-2769523182.py\u001b[0m in \u001b[0;36mbuild_probe_path\u001b[0;34m(hidden_base, dir_vec, steps, tau)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mdir_seq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexpand_delta_to_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdir_vec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq_len\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# (seq_len, d)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0mts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinspace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mtau\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtau\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m     \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mhidden_base\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mdir_seq\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mts\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (5,768) (5,4) "
          ]
        }
      ],
      "source": [
        "# ARM_transformer_scaffold.py\n",
        "# Requires: torch, transformers, numpy, scikit-learn, ripser, scipy, umap-learn (install via pip)\n",
        "# pip install torch transformers scikit-learn ripser scipy umap-learn\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.neighbors import kneighbors_graph\n",
        "from sklearn.manifold import spectral_embedding\n",
        "from ripser import ripser\n",
        "from sklearn.metrics import pairwise_distances\n",
        "from typing import List, Tuple, Dict, Any\n",
        "import math\n",
        "\n",
        "# -----------------------\n",
        "# Configuration / defaults\n",
        "# -----------------------\n",
        "MODEL_NAME = \"distilgpt2\"   # small, efficient; switch to \"gpt2\" if you prefer\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# ARM hyperparams (safe defaults)\n",
        "N_SEEDS = 200\n",
        "PROBES_PER_SEED = 16\n",
        "STEPS_PER_PROBE = 9\n",
        "EPS = 0.03                 # perturbation magnitude (relative to hidden vector norm)\n",
        "LAYER_TO_PROBE = 6         # index of transformer block to inject perturbations (0-based)\n",
        "NEIGHBOR_PCA_SAMPLES = 128 # for local PCA when available\n",
        "MANIFOLD_MODES = 8         # Number of principal components to use for manifold\n",
        "\n",
        "# -----------------------\n",
        "# Utilities: load model\n",
        "# -----------------------\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
        "model = AutoModelForCausalLM.from_pretrained(MODEL_NAME, output_hidden_states=True).to(DEVICE)\n",
        "model.eval()\n",
        "\n",
        "# Helper: get token ids and attention mask\n",
        "def encode_prompt(prompt: str):\n",
        "    toks = tokenizer(prompt, return_tensors=\"pt\")\n",
        "    return toks[\"input_ids\"].to(DEVICE), toks[\"attention_mask\"].to(DEVICE)\n",
        "\n",
        "# -----------------------\n",
        "# Core: run forward from a chosen layer (block-wise)\n",
        "# -----------------------\n",
        "# We'll use the model.transformer.* components directly so we can inject altered hidden states.\n",
        "# For distilgpt2/gpt2 HF models, the transformer body is model.transformer consisting of:\n",
        "# - wte (token embeddings), wpe (position embeddings), drop, and h = list of blocks, ln_f.\n",
        "#\n",
        "# Strategy:\n",
        "# 1) Build initial hidden states (token embeddings + positions) up to the layer to probe.\n",
        "# 2) Optionally modify the residual stream at that layer (add delta).\n",
        "# 3) Run remaining transformer blocks from that layer onward to get final logits/hidden states.\n",
        "\n",
        "def build_initial_hidden(input_ids: torch.LongTensor):\n",
        "    # returns hidden states BEFORE block 0 (embedding+pos), shape (batch, seq_len, d_model)\n",
        "    wte = model.transformer.wte(input_ids)        # token embeddings\n",
        "    seq_len = input_ids.shape[1]\n",
        "    position_ids = torch.arange(seq_len, dtype=torch.long, device=DEVICE).unsqueeze(0)\n",
        "    wpe = model.transformer.wpe(position_ids)\n",
        "    hidden = wte + wpe  # shape batch x seq x d_model\n",
        "    hidden = model.transformer.drop(hidden)\n",
        "    return hidden\n",
        "\n",
        "def forward_from_layer(hidden: torch.Tensor, start_layer: int, attention_mask: torch.Tensor=None):\n",
        "    \"\"\"\n",
        "    hidden: (batch, seq, d_model) hidden state to feed to block start_layer\n",
        "    returns: final logits, final hidden, and list of intermediate hidden states (per layer)\n",
        "    \"\"\"\n",
        "    h = hidden\n",
        "    intermediates = []\n",
        "    # blocks are modules in model.transformer.h (list-like)\n",
        "    for i, block in enumerate(model.transformer.h):\n",
        "        if i < start_layer:\n",
        "            continue\n",
        "        h = block(h)[0] if isinstance(block(h), tuple) else block(h)\n",
        "        intermediates.append(h)\n",
        "    # final layer norm\n",
        "    h = model.transformer.ln_f(h)\n",
        "    # lm head (tie weights with wte)\n",
        "    # reshape for lm head: (batch*seq, d_model)\n",
        "    logits = F.linear(h, model.transformer.wte.weight)  # tied weights\n",
        "    return logits, h, intermediates\n",
        "\n",
        "# -----------------------\n",
        "# Seed / probe generation\n",
        "# -----------------------\n",
        "def get_seed_hidden(prompt: str, layer_idx: int) -> torch.Tensor:\n",
        "    \"\"\"\n",
        "    Returns hidden state at layer_idx just BEFORE running block layer_idx.\n",
        "    shape: (seq_len, d_model) - batch dim removed for simplicity\n",
        "    \"\"\"\n",
        "    input_ids, attn_mask = encode_prompt(prompt)\n",
        "    hidden = build_initial_hidden(input_ids)  # batch x seq x d\n",
        "    # run blocks up to layer_idx-1 to get hidden state to modify\n",
        "    h = hidden\n",
        "    for i, block in enumerate(model.transformer.h):\n",
        "        if i >= layer_idx:\n",
        "            break\n",
        "        h = block(h)[0] if isinstance(block(h), tuple) else block(h)\n",
        "    # h is batch x seq x d; return squeeze(0)\n",
        "    return h.squeeze(0).detach().cpu()  # move to CPU numpy-friendly\n",
        "\n",
        "def sample_probes_for_hidden(hidden_vec: np.ndarray, k: int = PROBES_PER_SEED, eps: float = EPS, manifold_basis: np.ndarray = None):\n",
        "    \"\"\"\n",
        "    hidden_vec: (seq_len, d) array (we'll flatten sequence dimension to treat as a single vector or pool)\n",
        "    Return: probe_deltas shape (k, d) or (k, seq_len, d)\n",
        "    Approach: get global direction sampling in hidden-space.\n",
        "    - If manifold_basis is provided, sample directions within the manifold subspace.\n",
        "    - Otherwise, start with isotropic Gaussian directions normalized,\n",
        "      then scale to magnitude eps * ||hidden_vec|| (per token or pooled).\n",
        "    \"\"\"\n",
        "    # pool hidden to a single vector per seed (mean over tokens) for direction construction,\n",
        "    # but we will expand deltas per token when injecting.\n",
        "    pooled = hidden_vec.mean(axis=0)   # (d,)\n",
        "    d = pooled.shape[0]\n",
        "    rng = np.random.default_rng()\n",
        "\n",
        "    if manifold_basis is not None:\n",
        "        # Sample random coefficients for the manifold basis\n",
        "        coeffs = rng.normal(size=(k, manifold_basis.shape[1]))\n",
        "        # Construct directions as linear combinations of basis vectors\n",
        "        dirs = coeffs @ manifold_basis.T  # (k, d)\n",
        "    else:\n",
        "        dirs = rng.normal(size=(k, d))\n",
        "\n",
        "    dirs = dirs / (np.linalg.norm(dirs, axis=1, keepdims=True) + 1e-12)\n",
        "    hidden_norm = np.linalg.norm(pooled) + 1e-12\n",
        "    scale = eps * hidden_norm\n",
        "    dirs = dirs * scale\n",
        "    return dirs  # (k, d)\n",
        "\n",
        "def expand_delta_to_sequence(delta_vec: np.ndarray, seq_len: int):\n",
        "    # replicate delta_vec for each token position (simple approach)\n",
        "    return np.tile(delta_vec[None, :], (seq_len, 1))  # (seq_len, d)\n",
        "\n",
        "# -----------------------\n",
        "# Probe path: generate small path along a direction\n",
        "# -----------------------\n",
        "def build_probe_path(hidden_base: np.ndarray, dir_vec: np.ndarray, steps: int = STEPS_PER_PROBE, tau: float = 1.0):\n",
        "    \"\"\"\n",
        "    hidden_base: (seq_len, d)\n",
        "    dir_vec: (d,) pooled direction; will be expanded across seq positions\n",
        "    Returns: list of perturbed hidden tensors (steps long)\n",
        "    \"\"\"\n",
        "    seq_len = hidden_base.shape[0]\n",
        "    dir_seq = expand_delta_to_sequence(dir_vec, seq_len)  # (seq_len, d)\n",
        "    ts = np.linspace(-tau, tau, steps)\n",
        "    path = [hidden_base + (t * dir_seq) for t in ts]\n",
        "    return path, ts\n",
        "\n",
        "# -----------------------\n",
        "# Activation / response collection\n",
        "# -----------------------\n",
        "def activation_matrix_for_seed(prompt: str, layer_idx: int, k: int = PROBES_PER_SEED, m: int = STEPS_PER_PROBE, eps: float = EPS, manifold_basis: np.ndarray = None):\n",
        "    \"\"\"\n",
        "    For one seed prompt, sample k probes, each with m steps; forward from layer_idx\n",
        "    Collect features for each sample (e.g., final logits pooled, or final hidden pooled)\n",
        "    Return: A matrix of shape (k*m, f) for downstream analysis.\n",
        "    \"\"\"\n",
        "    hidden_base = get_seed_hidden(prompt, layer_idx).numpy()  # (seq_len, d)\n",
        "    seq_len, d = hidden_base.shape\n",
        "    deltas = sample_probes_for_hidden(hidden_base, k=k, eps=eps, manifold_basis=manifold_basis)\n",
        "    rows = []\n",
        "    for j in range(k):\n",
        "        path, ts = build_probe_path(hidden_base, deltas[j], steps=m)\n",
        "        for hidden_pert in path:\n",
        "            # run from layer_idx with this perturbed hidden\n",
        "            # convert to tensor with batch dim\n",
        "            h_t = torch.tensor(hidden_pert[None, :, :], dtype=torch.float32, device=DEVICE)\n",
        "            logits, final_h, intermediates = forward_from_layer(h_t, start_layer=layer_idx, attention_mask=None)\n",
        "            # choose feature vector to represent response:\n",
        "            # Option A: pooled logits over last token\n",
        "            # last_token_logits = logits[0, -1, :].detach().cpu().numpy()  # (vocab,)\n",
        "            # Option B (more compact): mean-pooled final hidden representation\n",
        "            feat = final_h.squeeze(0).mean(dim=0).detach().cpu().numpy()  # (d,)\n",
        "            rows.append(feat)\n",
        "    A = np.stack(rows, axis=0)  # (k*m, f) where f == d in this choice\n",
        "    return A\n",
        "\n",
        "# -----------------------\n",
        "# Resonance signature (SVD-based)\n",
        "# -----------------------\n",
        "def resonance_signature(A: np.ndarray, n_modes: int = 8) -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    Compute SVD stats and compact resonance signature for activation matrix A (n_samples x f).\n",
        "    Returns dict with normalized singular values, entropy, participation ratio, top modes.\n",
        "    \"\"\"\n",
        "    # center\n",
        "    A0 = A - A.mean(axis=0, keepdims=True)\n",
        "    # SVD (economy)\n",
        "    U, s, Vt = np.linalg.svd(A0, full_matrices=False)\n",
        "    s = np.maximum(s, 1e-12)\n",
        "    s_norm = s / s.sum()\n",
        "    entropy = -np.sum(s_norm * np.log(s_norm + 1e-12))\n",
        "    # participation ratio (measure of mode concentration)\n",
        "    pr = (s**2).sum()**2 / (np.sum(s**4) + 1e-12)\n",
        "    sig = {\n",
        "        \"singular_values\": s[:n_modes],\n",
        "        \"s_norm\": s_norm[:n_modes],\n",
        "        \"entropy\": float(entropy),\n",
        "        \"participation\": float(pr),\n",
        "        # optionally return top singular vectors (Vt[:n_modes,:]) if needed\n",
        "    }\n",
        "    return sig\n",
        "\n",
        "# -----------------------\n",
        "# Local topology via persistent homology\n",
        "# -----------------------\n",
        "def local_persistence_diagram(A: np.ndarray, maxdim: int = 1) -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    Compute persistence diagrams from the sample points A (n_points x f).\n",
        "    Use pairwise distances -> ripser with distance matrix True.\n",
        "    Returns ripser output (dgms).\n",
        "    \"\"\"\n",
        "    # compute pairwise distances to reduce memory in ripser call\n",
        "    D = pairwise_distances(A)\n",
        "    r = ripser(D, distance_matrix=True, maxdim=maxdim)\n",
        "    dgms = r[\"dgms\"]  # list of arrays for dimensions [0], [1], ...\n",
        "    return {\"diagrams\": dgms}\n",
        "\n",
        "# -----------------------\n",
        "# Descriptor assembly for one seed\n",
        "# -----------------------\n",
        "def descriptor_for_prompt(prompt: str, layer_idx: int, manifold_basis: np.ndarray = None):\n",
        "    \"\"\"\n",
        "    Run probes, compute A, then compute resonance signature + persistence.\n",
        "    Return a compact descriptor dict and flattened vector for graph building.\n",
        "    \"\"\"\n",
        "    A = activation_matrix_for_seed(prompt, layer_idx, manifold_basis=manifold_basis)\n",
        "    R = resonance_signature(A)\n",
        "    PD = local_persistence_diagram(A)\n",
        "    # flatten descriptor to a vector: use top-n singular values + entropy + participation + persistence stats\n",
        "    top_sv = R[\"s_norm\"][:6]\n",
        "    entropy = R[\"entropy\"]\n",
        "    part = R[\"participation\"]\n",
        "    # summary persistence features: count of significant 1D features (persistence > threshold)\n",
        "    d1 = PD[\"diagrams\"][1] if len(PD[\"diagrams\"]) > 1 else np.zeros((0,2))\n",
        "    pers_threshold = 0.05 * np.max(pairwise_distances(A)) if A.shape[0] > 1 else 0  # heuristic, handle single point case\n",
        "    n_1d_significant = np.sum((d1[:,1] - d1[:,0]) > pers_threshold) if d1.size else 0\n",
        "    vec = np.concatenate([top_sv, [entropy, part, n_1d_significant]])\n",
        "    return {\"A\": A, \"R\": R, \"PD\": PD, \"vec\": vec, \"prompt\": prompt}\n",
        "\n",
        "\n",
        "# -----------------------\n",
        "# Manifold representation\n",
        "# -----------------------\n",
        "def compute_manifold_basis(example_prompts: List[str], layer_idx: int, n_components: int = MANIFOLD_MODES):\n",
        "    \"\"\"\n",
        "    Compute hidden states for example prompts and find the top PCA components.\n",
        "    Returns the principal components (basis vectors).\n",
        "    \"\"\"\n",
        "    hidden_states = []\n",
        "    for prompt in example_prompts:\n",
        "        hidden = get_seed_hidden(prompt, layer_idx).numpy()  # (seq_len, d)\n",
        "        # Pool across sequence length for simplicity\n",
        "        pooled_hidden = hidden.mean(axis=0)  # (d,)\n",
        "        hidden_states.append(pooled_hidden)\n",
        "    H = np.stack(hidden_states, axis=0)  # (n_examples, d)\n",
        "    # Ensure n_components does not exceed the number of samples\n",
        "    n_components_actual = min(n_components, H.shape[0])\n",
        "    if n_components_actual == 0:\n",
        "        print(\"Warning: No manifold prompts provided, cannot compute manifold basis.\")\n",
        "        return np.array([]) # Return empty array if no prompts\n",
        "    pca = PCA(n_components=n_components_actual)\n",
        "    pca.fit(H)\n",
        "    return pca.components_  # (n_components_actual, d)\n",
        "\n",
        "\n",
        "# -----------------------\n",
        "# Build global atlas from many seeds\n",
        "# -----------------------\n",
        "def build_atlas(prompts: List[str], layer_idx: int, n_neighbors: int = 8, manifold_basis: np.ndarray = None):\n",
        "    \"\"\"\n",
        "    Build a global atlas of prompts by computing descriptors and their spectral embedding.\n",
        "    Can accept a larger list of prompts.\n",
        "    \"\"\"\n",
        "    descriptors = []\n",
        "    vecs = []\n",
        "    for i, p in enumerate(prompts):\n",
        "        # Add a progress indicator for potentially large numbers of prompts\n",
        "        print(f\"Processing prompt {i+1}/{len(prompts)}...\")\n",
        "        d = descriptor_for_prompt(p, layer_idx, manifold_basis=manifold_basis)\n",
        "        descriptors.append(d)\n",
        "        vecs.append(d[\"vec\"])\n",
        "    X = np.stack(vecs, axis=0)  # n_seeds x dim\n",
        "    # kNN graph adjacency (distance)\n",
        "    W = kneighbors_graph(X, n_neighbors=n_neighbors, mode=\"distance\", include_self=False).toarray()\n",
        "    # spectral embedding for visualization\n",
        "    emb = spectral_embedding(W + W.T, n_components=3)\n",
        "    return {\"descriptors\": descriptors, \"X\": X, \"W\": W, \"emb\": emb}\n",
        "\n",
        "# -----------------------\n",
        "# Simple iterative (greedy) proximal steering operator\n",
        "# -----------------------\n",
        "def steer_toward_manifold_resonance(seed_prompt: str, target_signature: np.ndarray, layer_idx: int, manifold_basis: np.ndarray, iters: int = 6, candidates: int = 12):\n",
        "    \"\"\"\n",
        "    Greedy search: at each step propose candidate deltas restricted to manifold directions, evaluate resulting resonance distance to target,\n",
        "    choose the best, and update the hidden state.\n",
        "    \"\"\"\n",
        "    # start hidden\n",
        "    hidden_base = get_seed_hidden(seed_prompt, layer_idx).numpy()  # (seq_len, d)\n",
        "    seq_len, d = hidden_base.shape\n",
        "    current_hidden = hidden_base.copy()\n",
        "\n",
        "    for it in range(iters):\n",
        "        # propose candidates within the manifold subspace\n",
        "        rng = np.random.default_rng()\n",
        "        # Sample random coefficients for the manifold basis\n",
        "        coeffs = rng.normal(size=(candidates, manifold_basis.shape[0]))\n",
        "        # Construct candidate deltas as linear combinations of basis vectors\n",
        "        cand_dirs = coeffs @ manifold_basis  # (candidates, d)\n",
        "\n",
        "        # Normalize and scale candidates\n",
        "        cand_dirs = cand_dirs / (np.linalg.norm(cand_dirs, axis=1, keepdims=True) + 1e-12)\n",
        "        scales = np.linspace(-EPS, EPS, 5)\n",
        "\n",
        "        best_score = float(\"inf\")\n",
        "        best_hidden_update = None\n",
        "\n",
        "        for cd in cand_dirs:\n",
        "            for s in scales:\n",
        "                delta = cd * s * (np.linalg.norm(current_hidden.mean(axis=0)) + 1e-12)\n",
        "                perturbed_hidden = current_hidden + expand_delta_to_sequence(delta, seq_len)\n",
        "\n",
        "                # forward and compute final pooled hidden (cheap shortcut)\n",
        "                h_t = torch.tensor(perturbed_hidden[None, :, :], dtype=torch.float32, device=DEVICE)\n",
        "                _, final_h, _ = forward_from_layer(h_t, start_layer=layer_idx)\n",
        "                feat = final_h.squeeze(0).mean(dim=0).detach().cpu().numpy()\n",
        "\n",
        "                # compute simple proxy signature: projection on top eigenvector (cheap)\n",
        "                # Here we create a tiny matrix with just this feat to plug into resonance_signature (works but trivial)\n",
        "                sig = resonance_signature(np.stack([feat], axis=0))\n",
        "                # distance: compare sig[\"s_norm\"] to target_signature (assumed same length)\n",
        "                cand_vec = sig[\"s_norm\"][:len(target_signature)]\n",
        "                score = np.linalg.norm(cand_vec - target_signature)\n",
        "\n",
        "                if score < best_score:\n",
        "                    best_score = score\n",
        "                    best_hidden_update = perturbed_hidden\n",
        "\n",
        "        # apply best_hidden_update as new current_hidden (proximal step)\n",
        "        if best_hidden_update is None:\n",
        "            break\n",
        "        current_hidden = best_hidden_update\n",
        "\n",
        "    # produce final text by forwarding from layer with current_hidden\n",
        "    h_t = torch.tensor(current_hidden[None, :, :], dtype=torch.float32, device=DEVICE)\n",
        "    logits, final_h, _ = forward_from_layer(h_t, start_layer=layer_idx)\n",
        "    # decode greedy token for next token\n",
        "    next_token = torch.argmax(logits[0, -1, :]).item()\n",
        "    return tokenizer.decode([next_token]), best_score\n",
        "\n",
        "# -----------------------\n",
        "# Example usage\n",
        "# -----------------------\n",
        "if __name__ == \"__main__\":\n",
        "    # quick test prompts for atlas\n",
        "    atlas_prompts = [\n",
        "        \"The capital of France is\",\n",
        "        \"The capital of Germany is\",\n",
        "        \"I love reading about physics because\",\n",
        "        \"The chef seasoned the soup with\",\n",
        "        \"Quantum entanglement is best described as\"\n",
        "    ]\n",
        "\n",
        "    # Example prompts for defining a manifold (e.g., \"Paris-style factual completions\")\n",
        "    manifold_prompts = [\n",
        "        \"The capital of Italy is\",\n",
        "        \"The largest city in Spain is\",\n",
        "        \"Mount Everest is located in\",\n",
        "        \"The currency of Japan is\"\n",
        "    ]\n",
        "\n",
        "    # Compute manifold basis\n",
        "    manifold_basis = compute_manifold_basis(manifold_prompts, layer_idx=LAYER_TO_PROBE, n_components=MANIFOLD_MODES)\n",
        "    print(f\"Computed manifold basis with shape: {manifold_basis.shape}\")\n",
        "\n",
        "    # compute atlas (descriptors may be somewhat slow; reduce N_SEEDS for testing)\n",
        "    # Pass the manifold basis to build_atlas to potentially see how descriptors within the manifold space cluster\n",
        "    atlas = build_atlas(atlas_prompts, layer_idx=LAYER_TO_PROBE, n_neighbors=3, manifold_basis=manifold_basis)\n",
        "    print(\"Spectral embedding shape:\", atlas[\"emb\"].shape)\n",
        "\n",
        "    # pick a seed and compute its descriptor (using the manifold basis)\n",
        "    d = descriptor_for_prompt(\"The capital of France is\", layer_idx=LAYER_TO_PROBE, manifold_basis=manifold_basis)\n",
        "    print(\"Descriptor vector (manifold-aware):\", d[\"vec\"])\n",
        "\n",
        "    # Example target signature for steering (pick a seed's signature within the manifold)\n",
        "    # For demonstration, let's use the signature of \"The capital of Italy is\" as the target\n",
        "    target_descriptor = descriptor_for_prompt(\"The capital of Italy is\", layer_idx=LAYER_TO_PROBE, manifold_basis=manifold_basis)\n",
        "    target_sig = target_descriptor[\"R\"][\"s_norm\"][:6]\n",
        "    print(\"Target signature (from 'The capital of Italy is'):\", target_sig)\n",
        "\n",
        "\n",
        "    out_token, score = steer_toward_manifold_resonance(\"The capital of Ger\", target_sig, layer_idx=LAYER_TO_PROBE, manifold_basis=manifold_basis)\n",
        "    print(\"Steered next-token:\", out_token, \"score:\", score)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "043b71d6"
      },
      "source": [
        "!pip install -q gradio"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8cd5dcd0"
      },
      "source": [
        "import gradio as gr\n",
        "import re # Import regular expression module for splitting sentences\n",
        "\n",
        "def split_sentences(text):\n",
        "    # Split text into sentences using common punctuation marks\n",
        "    sentences = re.split(r'(?<!\\w\\.\\w.)(?<![A-Z][a-z]\\.)(?<=\\.|\\?|\\!)\\s', text)\n",
        "    return [s.strip() for s in sentences if s.strip()]\n",
        "\n",
        "def run_steering_gradio(prompt, manifold_file):\n",
        "    if not prompt:\n",
        "        return \"Please enter a prompt for steering.\"\n",
        "\n",
        "    current_manifold_prompts = []\n",
        "    if manifold_file:\n",
        "        try:\n",
        "            # Read manifold prompts from the uploaded file\n",
        "            file_content = manifold_file.read().decode(\"utf-8\")\n",
        "            current_manifold_prompts = split_sentences(file_content)\n",
        "        except Exception as e:\n",
        "            return f\"Error reading or processing manifold file: {e}\"\n",
        "    else:\n",
        "         # Use default manifold prompts if no file is uploaded\n",
        "         # Assuming manifold_prompts is defined globally or accessible\n",
        "         global manifold_prompts\n",
        "         current_manifold_prompts = manifold_prompts\n",
        "\n",
        "    if not current_manifold_prompts:\n",
        "        return \"Please provide manifold prompts either via file or default.\"\n",
        "\n",
        "    output_text = f\"Using manifold prompts ({len(current_manifold_prompts)}): {current_manifold_prompts[:5]}...\\n\" # Show only first 5 for brevity\n",
        "\n",
        "    try:\n",
        "        # Compute manifold basis based on current input\n",
        "        current_manifold_basis = compute_manifold_basis(current_manifold_prompts, layer_idx=LAYER_TO_PROBE, n_components=MANIFOLD_MODES)\n",
        "        output_text += f\"Computed manifold basis with shape: {current_manifold_basis.shape}\\n\"\n",
        "\n",
        "        # For demonstration, use the signature of the first manifold prompt as the target\n",
        "        if current_manifold_prompts:\n",
        "             target_descriptor = descriptor_for_prompt(current_manifold_prompts[0], layer_idx=LAYER_TO_PROBE, manifold_basis=current_manifold_basis)\n",
        "             target_sig = target_descriptor[\"R\"][\"s_norm\"][:6]\n",
        "             output_text += f\"Target signature (from first manifold prompt): {target_sig}\\n\"\n",
        "        else:\n",
        "             output_text += \"No manifold prompts provided to determine target signature.\\n\"\n",
        "             return output_text\n",
        "\n",
        "        # Store computed basis and target signature for testing phase\n",
        "        global current_manifold_basis_global, target_sig_global\n",
        "        current_manifold_basis_global = current_manifold_basis\n",
        "        target_sig_global = target_sig\n",
        "\n",
        "        output_text += \"\\nManifold constructed. You can now test steering below.\\n\"\n",
        "\n",
        "\n",
        "    except Exception as e:\n",
        "        output_text += f\"An error occurred during manifold construction: {e}\\n\"\n",
        "        import traceback\n",
        "        output_text += traceback.format_exc()\n",
        "\n",
        "    return output_text\n",
        "\n",
        "def test_steering_gradio(test_prompt):\n",
        "    if not test_prompt:\n",
        "        return \"Please enter a prompt to test steering.\"\n",
        "\n",
        "    global current_manifold_basis_global, target_sig_global\n",
        "    if current_manifold_basis_global is None or target_sig_global is None:\n",
        "        return \"Please construct the manifold first by clicking the 'GO!' button.\"\n",
        "\n",
        "    output_text = f\"Testing steering for prompt: '{test_prompt}'\\n\"\n",
        "\n",
        "    try:\n",
        "        out_token, score = steer_toward_manifold_resonance(test_prompt, target_sig_global, layer_idx=LAYER_TO_PROBE, manifold_basis=current_manifold_basis_global)\n",
        "        output_text += f\"Steered next-token: {out_token}, score: {score}\\n\"\n",
        "    except Exception as e:\n",
        "        output_text += f\"An error occurred during steering: {e}\\n\"\n",
        "        import traceback\n",
        "        output_text += traceback.format_exc()\n",
        "\n",
        "    return output_text\n",
        "\n",
        "\n",
        "# Initialize global variables\n",
        "current_manifold_basis_global = None\n",
        "target_sig_global = None\n",
        "\n",
        "\n",
        "# Create the Gradio interface\n",
        "with gr.Blocks() as demo:\n",
        "    gr.Markdown(\"## ARM Manifold Steering\")\n",
        "\n",
        "    with gr.Tab(\"Manifold Construction\"):\n",
        "        manifold_file_input = gr.File(label=\"Upload a text file with manifold prompts\")\n",
        "        go_button = gr.Button(\"GO!\")\n",
        "        construction_output = gr.Textbox(label=\"Construction Output\", lines=10)\n",
        "\n",
        "        go_button.click(\n",
        "            run_steering_gradio,\n",
        "            inputs=[gr.Textbox(visible=False), manifold_file_input], # Dummy prompt input for function signature\n",
        "            outputs=construction_output\n",
        "        )\n",
        "\n",
        "    with gr.Tab(\"Test Steering\"):\n",
        "        test_prompt_input = gr.Textbox(label=\"Enter prompt to test steering\", lines=3)\n",
        "        test_button = gr.Button(\"Test Steering\")\n",
        "        test_output = gr.Textbox(label=\"Test Output\", lines=10)\n",
        "\n",
        "        test_button.click(\n",
        "            test_steering_gradio,\n",
        "            inputs=[test_prompt_input],\n",
        "            outputs=test_output\n",
        "        )\n",
        "\n",
        "\n",
        "demo.launch()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a11feb96"
      },
      "source": [
        "import ipywidgets as widgets\n",
        "from IPython.display import display\n",
        "\n",
        "prompt_input = widgets.Textarea(\n",
        "    value='',\n",
        "    placeholder='Enter your prompt here',\n",
        "    description='Prompt:',\n",
        "    disabled=False,\n",
        "    layout={'width': '500px', 'height': '100px'}\n",
        ")\n",
        "\n",
        "manifold_prompts_input = widgets.Textarea(\n",
        "    value='\\n'.join(manifold_prompts), # Use existing manifold_prompts as default\n",
        "    placeholder='Enter manifold prompts (one per line)',\n",
        "    description='Manifold Prompts:',\n",
        "    disabled=False,\n",
        "    layout={'width': '500px', 'height': '150px'}\n",
        ")\n",
        "\n",
        "\n",
        "output_area = widgets.Output()\n",
        "\n",
        "run_button = widgets.Button(description=\"Run Steering\")\n",
        "\n",
        "def run_steering(b):\n",
        "    with output_area:\n",
        "        output_area.clear_output()\n",
        "        prompt = prompt_input.value\n",
        "        current_manifold_prompts = manifold_prompts_input.value.splitlines()\n",
        "\n",
        "        if not prompt:\n",
        "            print(\"Please enter a prompt.\")\n",
        "            return\n",
        "        if not current_manifold_prompts:\n",
        "            print(\"Please enter manifold prompts.\")\n",
        "            return\n",
        "\n",
        "        print(f\"Running steering for prompt: '{prompt}'\")\n",
        "        print(f\"Using manifold prompts: {current_manifold_prompts}\")\n",
        "\n",
        "        try:\n",
        "            # Recompute manifold basis based on current input\n",
        "            current_manifold_basis = compute_manifold_basis(current_manifold_prompts, layer_idx=LAYER_TO_PROBE, n_components=MANIFOLD_MODES)\n",
        "            print(f\"Computed manifold basis with shape: {current_manifold_basis.shape}\")\n",
        "\n",
        "            # For demonstration, use the signature of the first manifold prompt as the target\n",
        "            if current_manifold_prompts:\n",
        "                 target_descriptor = descriptor_for_prompt(current_manifold_prompts[0], layer_idx=LAYER_TO_PROBE, manifold_basis=current_manifold_basis)\n",
        "                 target_sig = target_descriptor[\"R\"][\"s_norm\"][:6]\n",
        "                 print(\"Target signature (from first manifold prompt):\", target_sig)\n",
        "            else:\n",
        "                 print(\"No manifold prompts provided to determine target signature.\")\n",
        "                 return\n",
        "\n",
        "\n",
        "            out_token, score = steer_toward_manifold_resonance(prompt, target_sig, layer_idx=LAYER_TO_PROBE, manifold_basis=current_manifold_basis)\n",
        "            print(\"Steered next-token:\", out_token, \"score:\", score)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"An error occurred: {e}\")\n",
        "\n",
        "\n",
        "run_button.on_click(run_steering)\n",
        "\n",
        "display(prompt_input, manifold_prompts_input, run_button, output_area)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}